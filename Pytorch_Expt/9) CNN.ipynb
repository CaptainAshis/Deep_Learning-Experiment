{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1) Load Dataset\n",
    "# 2) Make dataset iterable\n",
    "# 3)Create Model class\n",
    "# 4) Instantiate Model Class\n",
    "# 5) Instantiate Loss Class\n",
    "# 6) Instantiate optimizer Class\n",
    "# 7) Tran Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1:-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import  torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "# Variables is for instantiating and assigning variables to a object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reaad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset=dsets.MNIST(root='./data' ,train=True,transform=transforms.ToTensor())#Train data\n",
    "test_dataset=dsets.MNIST(root='./data' ,train=False,transform=transforms.ToTensor())#Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  0,  4,  ...,  5,  6,  8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "\n",
    "n_iters=3000\n",
    "\n",
    "num_epochs=n_iters/(len(train_dataset)/batch_size)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All goodness from pytorch -nn.Module\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel,self).__init__() #Super inheritance function\n",
    "#         Convolution-1\n",
    "        self.cnn1=nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5, stride=1,padding=2) \n",
    "#     #2dimension, in_channels=1 bcoz of mnist grayscale,    Output channels = 16(no of kernels)hence 16 feature maps\n",
    "#  \n",
    "        self.relu1=nn.ReLU()\n",
    "#     After eveery convolution layer pass it through the non linearity, Relu is best non linear function\n",
    "\n",
    "\n",
    "#         Max pool 1\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "#         Convolution 2\n",
    "        self.cnn2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=2)\n",
    "#     in_channels=16 and output-channels=32\n",
    "        self.relu2=nn.ReLU()\n",
    "#         MAxpool 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "#         Fully connected 1 --- 32*7*7 has been calculated and 10 is the mnist dataset output\n",
    "        self.fc1=nn.Linear(32*7*7,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "#         Convolution 1\n",
    "        out=self.cnn1(x)\n",
    "        out=self.relu1(out)\n",
    "        \n",
    "#         MAxpool1\n",
    "        out=self.maxpool1(out)\n",
    "        \n",
    "#         Convolution 2\n",
    "        out=self.cnn2(out)\n",
    "        out=self.relu2(out)\n",
    "#         Maxpool 2\n",
    "        out=self.maxpool2(out)\n",
    "#         Resize\n",
    "# Original size (100,32,7,7) Input size \n",
    "# out.size(0):-100 is the batch size of 100\n",
    "# New out size (100,32*7*7) , this is what linear function requires, we cannot feed a linear funcion of 3d here but \n",
    "# only 1 single dimension here.\n",
    "        out=out.view(out.size(0),-1)\n",
    "#     -1 means reshape to the remaining value which is 32*7*7 here, so that output can be feed to the linear function\n",
    "        \n",
    "        out=self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 :-Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 5:-Instantiate Loss class\n",
    "# CNN-CrossEntropyLoss\n",
    "# Feedforward NN- CrossEntropyLoss\n",
    "# LogisticRegression- CrossEntropyLoss\n",
    "# Linear Regression - MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 6 -Instantiate Optimizer Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=.01\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNModel(\n",
      "  (cnn1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000003C9EEE8E60>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(list(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[0].size())\n",
    "# 16 kernels of 5*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[2].size())\n",
    "# 32 kernels of 5*5 and depth 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[3].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1568])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[4].size())\n",
    "# Reshaping gives 1568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Step 7 -Train Model\n",
    "###### 1) convert input/labels into Variables \n",
    "######       cnn input (1,28,28)\n",
    "######       Feedforward nn input(1,28*28)\n",
    "###### 2) Clear Gradient buffers\n",
    "###### 3) Get outputs given inputs\n",
    "###### 4) Get Loss\n",
    "###### 5)Get gradients wrt parameters\n",
    "###### 6) Update parameters using gradients\n",
    "###### 7)Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis.panda\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 500. Loss 0.4349491000175476. Acuracy 88.01.\n",
      "Iterations 1000. Loss 0.3766486644744873. Acuracy 92.05.\n",
      "Iterations 1500. Loss 0.3643883764743805. Acuracy 94.17.\n",
      "Iterations 2000. Loss 0.0985739678144455. Acuracy 95.45.\n",
      "Iterations 2500. Loss 0.16918666660785675. Acuracy 96.34.\n",
      "Iterations 3000. Loss 0.05423809587955475. Acuracy 96.92.\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "for epoch in range(int(num_epochs)):\n",
    "    for i,(images,labels) in enumerate(train_loader):# 100 images per batch size, so 100 images at once . Every iteration\n",
    "#         feed 100 images.\n",
    "        images=Variable(images)\n",
    "#         print(images.size())\n",
    "        labels=Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model.forward(images)\n",
    "        \n",
    "        loss=criterion(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1\n",
    "        \n",
    "        if iter%500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            \n",
    "            for images,labels in test_loader:\n",
    "                images=Variable(images)\n",
    "                outputs=model(images)\n",
    "                \n",
    "                _,predicted=torch.max(outputs.data,1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                \n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=100*int(correct)/int(total)\n",
    "            \n",
    "            print('Iterations {}. Loss {}. Acuracy {}.'.format(iter,loss.data[0],accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
