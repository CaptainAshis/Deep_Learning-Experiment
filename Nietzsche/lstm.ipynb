{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_modified.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "e_EObDalmGg0",
        "colab_type": "code",
        "outputId": "963407e4-93e9-4ab2-d171-170f0b55ae3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2719
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install fastai==0.7.0\n",
        "! pip install torchtext==0.2.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/6d/9d0d6e17a78b0598d5e8c49a0d03ffc7ff265ae62eca3e2345fab14edb9b/fastai-0.7.0-py3-none-any.whl (112kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 3.8MB/s \n",
            "\u001b[?25hCollecting jupyter (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl\n",
            "Collecting widgetsnbextension (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.2MB 13.7MB/s \n",
            "\u001b[?25hCollecting graphviz (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Collecting feather-format (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/08/55/940b97cc6f19a19f5dab9efef2f68a0ce43a7632f858b272391f0b851a7e/feather-format-0.4.0.tar.gz\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.4.19)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (17.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)\n",
            "Collecting torchtext (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.5.1)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.28.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.3.0)\n",
            "Collecting sklearn-pandas (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/9c/c94f46b40b86d2c77c46c4c1b858fc66c117b4390665eca28f2e0812db45/sklearn_pandas-1.7.0-py2.py3-none-any.whl\n",
            "Collecting html5lib (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/62/bbd2be0e7943ec8504b517e62bab011b4946e1258842bc159e5dfde15b96/html5lib-1.0.1-py2.py3-none-any.whl (117kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 31.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)\n",
            "Collecting bcolz (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.10.15)\n",
            "Collecting jedi (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/1a/9bd24a185873b998611c2d8d4fb15cd5e8a879ead36355df7ee53e9111bf/jedi-0.13.1-py2.py3-none-any.whl (177kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 28.2MB/s \n",
            "\u001b[?25hCollecting torchvision (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 25.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.2)\n",
            "Collecting ipywidgets (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 28.7MB/s \n",
            "\u001b[?25hCollecting plotnine (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/02/b171c828560aea3a5da1efda464230dac3ef4f4834b88e0bd52ad14a08f0/plotnine-0.5.1-py2.py3-none-any.whl (3.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.6MB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.13)\n",
            "Collecting isoweek (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/d4/fe7e2637975c476734fcbf53776e650a29680194eb0dd21dbdc020ca92de/isoweek-1.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.1.7)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)\n",
            "Collecting pandas-summary (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/97/55/ea54109a4e7a8e7342bdf23e9382c858224263d984b0d95610568e564f59/pandas_summary-0.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.6.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)\n",
            "Collecting torch<0.4 (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/a5/e8b50b55b1abac9f1e3346c4242f1e42a82d368a8442cbd50c532922f6c4/torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (496.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 496.4MB 29kB/s \n",
            "\u001b[?25hCollecting jupyter-console (from jupyter->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.2.2)\n",
            "Collecting qtconsole (from jupyter->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/7a/8aefbc0ed078dec7951ac9a06dcd1869243ecd7bcbce26fa47bf5e469a8f/qtconsole-4.4.3-py2.py3-none-any.whl (113kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 29.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.4.0)\n",
            "Collecting pyarrow>=0.4.0 (from feather-format->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/94/23135312f97b20d6457294606fb70fad43ef93b7bffe567088ebe3623703/pyarrow-0.11.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 11.6MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (40.6.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bleach->fastai==0.7.0) (1.11.0)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pandas->fastai==0.7.0) (0.19.2)\n",
            "Collecting parso>=0.3.0 (from jedi->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/51/9c48a46334be50c13d25a3afe55fa05c445699304c5ad32619de953a2305/parso-0.3.1-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)\n",
            "Collecting descartes>=1.1.0 (from plotnine->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/b6/1ed2eb03989ae574584664985367ba70cd9cf8b32ee8cad0e8aaeac819f3/descartes-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.1)\n",
            "Collecting mizani>=0.5.2 (from plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/3a/1d1c5563b6aeb5fffda694b70d649a0f728a112b79a66b85a6af4814a643/mizani-0.5.2-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.46)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.5.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)\n",
            "Collecting palettable (from mizani>=0.5.2->plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/8a/84537c0354f0d1f03bf644b71bf8e0a50db9c1294181905721a5f3efbf66/palettable-3.1.1-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 24.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: feather-format, bcolz\n",
            "  Running setup.py bdist_wheel for feather-format ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/85/7d/12/2dfa5c0195f921ac935f5e8f27deada74972edc0ae9988a9c1\n",
            "  Running setup.py bdist_wheel for bcolz ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built feather-format bcolz\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mmizani 0.5.2 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.5.1 has requirement matplotlib>=3.0.0, but you'll have matplotlib 2.1.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.5.1 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jupyter-console, qtconsole, widgetsnbextension, ipywidgets, jupyter, graphviz, pyarrow, feather-format, torch, torchtext, sklearn-pandas, html5lib, bcolz, parso, jedi, torchvision, descartes, palettable, mizani, plotnine, isoweek, pandas-summary, fastai\n",
            "Successfully installed bcolz-1.2.1 descartes-1.1.0 fastai-0.7.0 feather-format-0.4.0 graphviz-0.10.1 html5lib-1.0.1 ipywidgets-7.4.2 isoweek-1.3.3 jedi-0.13.1 jupyter-1.0.0 jupyter-console-6.0.0 mizani-0.5.2 palettable-3.1.1 pandas-summary-0.0.5 parso-0.3.1 plotnine-0.5.1 pyarrow-0.11.1 qtconsole-4.4.3 sklearn-pandas-1.7.0 torch-0.3.1 torchtext-0.3.1 torchvision-0.2.1 widgetsnbextension-3.4.2\n",
            "Collecting torchtext==0.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (2.18.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2018.10.15)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i946v-PZmO4I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.io import *\n",
        "from fastai.conv_learner import *\n",
        "\n",
        "from fastai.column_data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vl8n3ocmWhr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH='data/nietzsche/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGYyuV-qmWKB",
        "colab_type": "code",
        "outputId": "8d80ea08-560d-4551-e971-98a4e3660276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
        "text = open(f'{PATH}nietzsche.txt').read()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt: 606kB [00:01, 355kB/s]                            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ybi66gB7mWGg",
        "colab_type": "code",
        "outputId": "8244775a-7b0b-4bb9-a7c1-fd6afa71da3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)+1\n",
        "print('total chars:', vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mja-YgeTmWBd",
        "colab_type": "code",
        "outputId": "206ec9b2-3229-4673-c443-d0b923b0ae5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "chars.insert(0, \"\\0\")\n",
        "\n",
        "''.join(chars[1:-6])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "_qDYPzMjmV7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_indices = {c: i for i, c in enumerate(chars)}\n",
        "indices_char = {i: c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lsYODVhxmV2B",
        "colab_type": "code",
        "outputId": "87f1ae04-3701-42b8-a145-723bf2b7e37a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "idx = [char_indices[c] for c in text]\n",
        "\n",
        "idx[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "A4J1S4GmmVvz",
        "colab_type": "code",
        "outputId": "59fdd318-fdd9-41f1-c45c-0c0ba478faf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext import vocab, data\n",
        "\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *\n",
        "\n",
        "PATH='/content/data/nietzsche/'\n",
        "\n",
        "TRN_PATH = 'TRN/'\n",
        "VAL_PATH = 'VAL/'\n",
        "TRN = f'{PATH}{TRN_PATH}'\n",
        "VAL = f'{PATH}{VAL_PATH}'\n",
        "\n",
        "# Note: The student needs to practice her shell skills and prepare her own dataset before proceeding:\n",
        "# - trn/trn.txt (first 80% of nietzsche.txt)\n",
        "# - val/val.txt (last 20% of nietzsche.txt)\n",
        "\n",
        "%ls {PATH}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FC3jsNAuno85",
        "colab_type": "code",
        "outputId": "f49cf861-c8aa-44f3-876a-4a23c05084c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt  \u001b[0m\u001b[01;34mTRN\u001b[0m/  trn.txt  \u001b[01;34mVAL\u001b[0m/  val.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ND9l4KK-mw8x",
        "colab_type": "code",
        "outputId": "2b7565ad-3283-4d5c-9423-a774dc67fd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd  data/nietzsche/\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/nietzsche\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C8C5HX-jtt5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir VAL\n",
        "!mkdir TRN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgTmoAVmmywB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f= open(\"trn.txt\",\"w+\")\n",
        "for i in range(len(text[:530000])):\n",
        "     f.write(text[i])\n",
        "f.close() \n",
        "\n",
        "f= open(\"val.txt\",\"w+\")\n",
        "for i in range(len(text[530000:])):\n",
        "     f.write(text[i])\n",
        "f.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j0bUmGgRm2Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ce705a1-1df4-4455-9a03-b9a931781e09"
      },
      "cell_type": "code",
      "source": [
        "# ! wc -m  val.txt\n",
        "! mv -v /content/data/nietzsche/val.txt /content/data/nietzsche/VAL/\n",
        "! mv -v /content/data/nietzsche/trn.txt /content/data/nietzsche/TRN/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed '/content/data/nietzsche/val.txt' -> '/content/data/nietzsche/VAL/val.txt'\n",
            "renamed '/content/data/nietzsche/trn.txt' -> '/content/data/nietzsche/TRN/trn.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WFAlGMc0m2S7",
        "colab_type": "code",
        "outputId": "1769f4d3-16b2-45aa-a3ef-eeee39916314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True, tokenize=list)\n",
        "bs=64; bptt=50; n_fac=100; n_hidden=1024\n",
        "\n",
        "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
        "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
        "\n",
        "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161, 55, 1, 521287)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "Y6bVkS0lnYL0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 512*2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMjA-hzHm2L8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import sgdr\n",
        "\n",
        "n_hidden=1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMsaCXnGm2Fz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
        "        super().__init__()\n",
        "        self.vocab_size,self.nl = vocab_size,nl\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs):\n",
        "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
        "                  V(torch.zeros(self.nl, bs, n_hidden)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TeVU_mzvm1_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 3).cuda()\n",
        "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cHmNzQLHm16x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{PATH}models', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94g1SnAYm12M",
        "colab_type": "code",
        "outputId": "1fc93547-442c-49db-ce1b-9559ce90c670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, lo.opt, F.nll_loss)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63e6d3e4e4164134bda6bd1f18edbb09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      3.058062   3.044033  \n",
            "    1      3.041689   3.044638  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([3.04464])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "nqfTfBrGm1wk",
        "colab_type": "code",
        "outputId": "f766fca4-fab6-49e4-f8e1-ee690fef0c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7f06a8337b64227b410b0f7926c5e14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=15, style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      3.016774   2.989205  \n",
            "    1      3.004507   2.997172  \n",
            "    2      2.940385   2.875598  \n",
            "    3      3.025433   3.003709  \n",
            "    4      2.844473   2.683357  \n",
            "    5      2.066826   1.826603  \n",
            "    6      1.743862   1.643534  \n",
            "    7      1.852061   1.697437  \n",
            "    8      1.712708   1.567653  \n",
            "    9      1.605037   1.470101  \n",
            "    10     1.517391   1.40102   \n",
            "    11     1.4405     1.334305  \n",
            "    12     1.372975   1.280644  \n",
            "    13     1.3177     1.238514  \n",
            "    14     1.290842   1.226868  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.22687])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "rYFvB2Ovm1rT",
        "colab_type": "code",
        "outputId": "80cebd7c-1f8c-4374-d441-10298f547361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1229
        }
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bcd5f5167b6418ab197da6e5d0f278e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.44048    1.313112  \n",
            "    1      1.488313   1.350004  \n",
            "    2      1.36552    1.267718  \n",
            "    3      1.488569   1.367849  \n",
            "    4      1.425236   1.302421  \n",
            "    5      1.334832   1.226359  \n",
            "    6      1.267407   1.196797  \n",
            "    7      1.476726   1.369066  \n",
            "    8      1.456075   1.341615  \n",
            "    9      1.408075   1.300758  \n",
            "    10     1.357125   1.252813  \n",
            "    11     1.306475   1.204362  \n",
            "    12     1.254089   1.154594  \n",
            "    13     1.202228   1.122787  \n",
            "    14     1.17207    1.11179   \n",
            "    15     1.457128   1.349205  \n",
            "    16     1.436052   1.320655  \n",
            "    17     1.41067    1.296875  \n",
            "    18     1.390619   1.289492  \n",
            "    19     1.368401   1.262586  \n",
            "    20     1.34629    1.249168  \n",
            "    21     1.319573   1.218542  \n",
            "    22     1.295882   1.193858  \n",
            "    23     1.264732   1.168474  \n",
            "    24     1.235027   1.142553  \n",
            "    25     1.197942   1.112822  \n",
            "    26     1.163695   1.076679  \n",
            "    27     1.127845   1.043957  \n",
            "    28     1.093791   1.015454  \n",
            "    29     1.061664   0.999674  \n",
            "    30     1.04863    0.99671   \n",
            "    31     1.407821   1.308871  \n",
            "    32     1.400106   1.283351  \n",
            "    33     1.380994   1.269118  \n",
            "    34     1.370093   1.258498  \n",
            "    35     1.361586   1.259069  \n",
            "    36     1.348636   1.241996  \n",
            "    37     1.339977   1.234151  \n",
            "    38     1.333243   1.225624  \n",
            "    39     1.323631   1.220659  \n",
            "    40     1.311093   1.208488  \n",
            "    41     1.302932   1.208082  \n",
            "    42     1.293679   1.189558  \n",
            "    43     1.280434   1.181382  \n",
            "    44     1.26867    1.169116  \n",
            "    45     1.256692   1.161918  \n",
            "    46     1.239744   1.145786  \n",
            "    47     1.223163   1.125951  \n",
            "    48     1.208923   1.114017  \n",
            "    49     1.190714   1.089468  \n",
            "    50     1.166025   1.072272  \n",
            "    51     1.140798   1.053369  \n",
            "    52     1.114408   1.027219  \n",
            "    53     1.087719   1.003101  \n",
            "    54     1.058354   0.970238  \n",
            "    55     1.029075   0.945873  \n",
            "    56     0.999371   0.91872   \n",
            "    57     0.988584   0.896895  \n",
            "    58     0.934806   0.868248  \n",
            "    59     0.924662   0.8472    \n",
            "    60     0.89058    0.829339  \n",
            "    61     0.901599   0.823408  \n",
            "    62     0.896875   0.824536  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.82454])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "wd9dtdN4m1k1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = TEXT.numericalize(inp)\n",
        "    p = m(VV(idxs.transpose(0,1)))\n",
        "    r = torch.multinomial(p[-1].exp(), 1)\n",
        "    return TEXT.vocab.itos[to_np(r)[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGMLp81Em1ce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UPvpc6vFnGUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4a2331b3-2eed-41d3-a54f-f0b4121ddac7"
      },
      "cell_type": "code",
      "source": [
        "print(get_next_n('for thos', 400))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for those bringing. it betrays (happinessimpally, requirement, down unduchmile for it (would lie fol actions! what isworda wrings. in case gives himself and begin to it. the proper rus! it may belief in the dreads to the tow, somethings at things; itbestin at otherwism. does not some new [look at a distracting--it was that attempters; such arrangement, shame-posterity insomuch as ever of feiting upon the \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OurXTuTSnGOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3jhQ9JlqnGJq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PHrgjqZenGCu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBC6c9UqnF8f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTrGKWYdnFy5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fd-N04E0nFrl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFmPep6-mRmw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}