{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson6_rnn(1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Rp9JBj890Hkv",
        "colab_type": "code",
        "outputId": "1450d89d-8cbf-40e9-8be8-09569fe538ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2719
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install fastai==0.7.0\n",
        "! pip install torchtext==0.2.3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/6d/9d0d6e17a78b0598d5e8c49a0d03ffc7ff265ae62eca3e2345fab14edb9b/fastai-0.7.0-py3-none-any.whl (112kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.10.15)\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)\n",
            "Collecting pandas-summary (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/97/55/ea54109a4e7a8e7342bdf23e9382c858224263d984b0d95610568e564f59/pandas_summary-0.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)\n",
            "Collecting graphviz (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
            "Collecting ipywidgets (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K    100% |████████████████████████████████| 112kB 4.7MB/s \n",
            "\u001b[?25hCollecting widgetsnbextension (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.2MB 8.8MB/s \n",
            "\u001b[?25hCollecting sklearn-pandas (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/9c/c94f46b40b86d2c77c46c4c1b858fc66c117b4390665eca28f2e0812db45/sklearn_pandas-1.7.0-py2.py3-none-any.whl\n",
            "Collecting feather-format (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/08/55/940b97cc6f19a19f5dab9efef2f68a0ce43a7632f858b272391f0b851a7e/feather-format-0.4.0.tar.gz\n",
            "Collecting isoweek (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/d4/fe7e2637975c476734fcbf53776e650a29680194eb0dd21dbdc020ca92de/isoweek-1.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.28.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.3.0)\n",
            "Collecting jupyter (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)\n",
            "Collecting jedi (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/1a/9bd24a185873b998611c2d8d4fb15cd5e8a879ead36355df7ee53e9111bf/jedi-0.13.1-py2.py3-none-any.whl (177kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.6.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.4.19)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.13)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)\n",
            "Collecting torchvision (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.5.1)\n",
            "Collecting torchtext (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/bc/b28b9efb4653c03e597ed207264eea45862b5260f48e9f010b5068d64db1/torchtext-0.3.1-py3-none-any.whl (62kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)\n",
            "Collecting bcolz (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.6)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.7)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (17.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)\n",
            "Collecting html5lib (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/62/bbd2be0e7943ec8504b517e62bab011b4946e1258842bc159e5dfde15b96/html5lib-1.0.1-py2.py3-none-any.whl (117kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.2)\n",
            "Collecting plotnine (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/02/b171c828560aea3a5da1efda464230dac3ef4f4834b88e0bd52ad14a08f0/plotnine-0.5.1-py2.py3-none-any.whl (3.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.6MB 10.9MB/s \n",
            "\u001b[?25hCollecting torch<0.4 (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/a5/e8b50b55b1abac9f1e3346c4242f1e42a82d368a8442cbd50c532922f6c4/torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (496.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 496.4MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.1.7)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bleach->fastai==0.7.0) (1.11.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.3)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension->fastai==0.7.0) (5.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pandas->fastai==0.7.0) (0.19.2)\n",
            "Collecting pyarrow>=0.4.0 (from feather-format->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/94/23135312f97b20d6457294606fb70fad43ef93b7bffe567088ebe3623703/pyarrow-0.11.1-cp36-cp36m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 11.6MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.4.0)\n",
            "Collecting jupyter-console (from jupyter->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl\n",
            "Collecting qtconsole (from jupyter->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/7a/8aefbc0ed078dec7951ac9a06dcd1869243ecd7bcbce26fa47bf5e469a8f/qtconsole-4.4.3-py2.py3-none-any.whl (113kB)\n",
            "\u001b[K    100% |████████████████████████████████| 122kB 27.2MB/s \n",
            "\u001b[?25hCollecting parso>=0.3.0 (from jedi->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/51/9c48a46334be50c13d25a3afe55fa05c445699304c5ad32619de953a2305/parso-0.3.1-py2.py3-none-any.whl (88kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 26.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.46)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.1)\n",
            "Collecting mizani>=0.5.2 (from plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/3a/1d1c5563b6aeb5fffda694b70d649a0f728a112b79a66b85a6af4814a643/mizani-0.5.2-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)\n",
            "Collecting descartes>=1.1.0 (from plotnine->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/b6/1ed2eb03989ae574584664985367ba70cd9cf8b32ee8cad0e8aaeac819f3/descartes-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (40.6.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)\n",
            "Collecting palettable (from mizani>=0.5.2->plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/8a/84537c0354f0d1f03bf644b71bf8e0a50db9c1294181905721a5f3efbf66/palettable-3.1.1-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 26.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: feather-format, bcolz\n",
            "  Running setup.py bdist_wheel for feather-format ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/85/7d/12/2dfa5c0195f921ac935f5e8f27deada74972edc0ae9988a9c1\n",
            "  Running setup.py bdist_wheel for bcolz ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built feather-format bcolz\n",
            "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mmizani 0.5.2 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.5.1 has requirement matplotlib>=3.0.0, but you'll have matplotlib 2.1.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.5.1 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas-summary, graphviz, widgetsnbextension, ipywidgets, sklearn-pandas, pyarrow, feather-format, isoweek, jupyter-console, qtconsole, jupyter, parso, jedi, torch, torchvision, torchtext, bcolz, html5lib, palettable, mizani, descartes, plotnine, fastai\n",
            "Successfully installed bcolz-1.2.1 descartes-1.1.0 fastai-0.7.0 feather-format-0.4.0 graphviz-0.10.1 html5lib-1.0.1 ipywidgets-7.4.2 isoweek-1.3.3 jedi-0.13.1 jupyter-1.0.0 jupyter-console-6.0.0 mizani-0.5.2 palettable-3.1.1 pandas-summary-0.0.5 parso-0.3.1 plotnine-0.5.1 pyarrow-0.11.1 qtconsole-4.4.3 sklearn-pandas-1.7.0 torch-0.3.1 torchtext-0.3.1 torchvision-0.2.1 widgetsnbextension-3.4.2\n",
            "Collecting torchtext==0.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (2.18.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (3.0.4)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Running setup.py bdist_wheel for torchtext ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f8PFHCe20Dn6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "from fastai.io import *\n",
        "from fastai.conv_learner import *\n",
        "\n",
        "from fastai.column_data import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9slvdiH0Dou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "fOme_wZe0Do7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We're going to download the collected works of Nietzsche to use as our data for this class."
      ]
    },
    {
      "metadata": {
        "id": "F3_MuXQw0DpG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH='data/nietzsche/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-aJIJAb0Dpq",
        "colab_type": "code",
        "outputId": "0e922b61-40c4-46be-e972-14ac4607c56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
        "text = open(f'{PATH}nietzsche.txt').read()\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt: 606kB [00:00, 1.73MB/s]                           "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "x-KpDu5T0Dqa",
        "colab_type": "code",
        "outputId": "ffc761e7-2b33-4fde-b53c-220d80a8ba93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "text[:400]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been unskilled and unseemly methods for\\nwinning a woman? Certainly she has never allowed herself '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "zgpNGO710Dq_",
        "colab_type": "code",
        "outputId": "56ed7fa2-0f07-4adb-f830-15865b9989d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)+1\n",
        "print('total chars:', vocab_size)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MEZaNMUA0Drk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Sometimes it's useful to have a zero value in the dataset, e.g. for padding"
      ]
    },
    {
      "metadata": {
        "id": "UBYbfcEG0Dr3",
        "colab_type": "code",
        "outputId": "aa81436e-8be4-4239-d278-b915c82d5869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "chars.insert(0, \"\\0\")\n",
        "\n",
        "''.join(chars[1:-6])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "pVOTSGCP0Dsj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Map from chars to indices and back again"
      ]
    },
    {
      "metadata": {
        "id": "-OwtMiVc0DtC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "char_indices = {c: i for i, c in enumerate(chars)}\n",
        "indices_char = {i: c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfAcy58W0Dtw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*idx* will be the data we use from now on - it simply converts all the characters to their index (based on the mapping above)"
      ]
    },
    {
      "metadata": {
        "id": "IY5tl62Z0Dt2",
        "colab_type": "code",
        "outputId": "426a1c1f-fd19-41f8-bd44-8abdd61793ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "idx = [char_indices[c] for c in text]\n",
        "\n",
        "idx[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ZaQchLBk0DuU",
        "colab_type": "code",
        "outputId": "1540717f-ce23-412c-c141-a8dbd14304f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "''.join(indices_char[i] for i in idx[:70])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "UYgMjQ9p0Dux",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Three char model"
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "yS8gifRJ0Du-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create inputs"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "u68ClRJ30DvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "l7OrjMHA0DvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cs=3\n",
        "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
        "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
        "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
        "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "y7lqwGTq0Dvz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our inputs"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "d9T9HjDv0Dv8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x1 = np.stack(c1_dat)\n",
        "x2 = np.stack(c2_dat)\n",
        "x3 = np.stack(c3_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "wLcOeszq0Dwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our output"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Y10UoU7D0Dwj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c4_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "719goqln0DxP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first 4 inputs and outputs"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": true,
        "id": "VgrVnEGb0DxY",
        "colab_type": "code",
        "outputId": "53c5d53d-4706-4978-ed30-ced2abb7f20f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x1[:4], x2[:4], x3[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "a77jaP8H0DyZ",
        "colab_type": "code",
        "outputId": "ef098bc7-5eca-403a-9c0d-d26d71185d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y[:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([30, 29,  1, 40])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "cWCJ-GPc0Dyw",
        "colab_type": "code",
        "outputId": "e2a4812d-7fb0-4c1f-8a24-74221a6403e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x1.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200297,), (200297,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Cvmel8D50DzY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "WUazkX5t0Dzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pick a size for our hidden state"
      ]
    },
    {
      "metadata": {
        "id": "8AhWel9v0Dzz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_hidden = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LL79ubqy0D0M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The number of latent factors to create (i.e. the size of the embedding matrix)"
      ]
    },
    {
      "metadata": {
        "id": "qgbwCPYc0D0T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_fac = 42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "py5hMBnm0D0e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Char3Model(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "\n",
        "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "\n",
        "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        \n",
        "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, c1, c2, c3):\n",
        "        in1 = F.relu(self.l_in(self.e(c1)))\n",
        "        in2 = F.relu(self.l_in(self.e(c2)))\n",
        "        in3 = F.relu(self.l_in(self.e(c3)))\n",
        "        \n",
        "        h = V(torch.zeros(in1.size()).cuda())\n",
        "        h = F.tanh(self.l_hidden(h+in1))\n",
        "        h = F.tanh(self.l_hidden(h+in2))\n",
        "        h = F.tanh(self.l_hidden(h+in3))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2BwJFts0D0x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bGVN1kss0D1c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = Char3Model(vocab_size, n_fac).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1B5NBRPc0D14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rdt_ts0-0D2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4YnDL1en0D25",
        "colab_type": "code",
        "outputId": "ce11348c-9d6c-4daf-a426-2ca8727d528b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73483a3ac1804c3e81c8de6744d5c4bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       2.09627  6.52849]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MfgRIPaZ0D3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZMf2tr90D3W",
        "colab_type": "code",
        "outputId": "c18c1431-2203-489c-dbc2-6cef9da013b9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7278ec0864e451795d91bac0ff944c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.84525  6.52312]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "4n2KkllD0D35",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "_qWTbLg50D3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "lYKvtstC0D4O",
        "colab_type": "code",
        "outputId": "431fdb8b-b5c7-4976-ce9a-c6ab73cc5d6c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('y. ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'T'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "0L4lV8Bu0D4l",
        "colab_type": "code",
        "outputId": "9719d00c-844d-43e9-a430-6a5994af99b0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('ppl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "2psIjMEe0D47",
        "colab_type": "code",
        "outputId": "60b33dd7-735b-4b0a-8db3-bee07b4a35b2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next(' th')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "fg4FH-O30D5i",
        "colab_type": "code",
        "outputId": "2e7a4081-f1da-492c-81b4-0ac868e30984",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('and')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "metadata": {
        "id": "u9fkjyN80D51",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Our first RNN!"
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "uGa7vIfU0D6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create inputs"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "47V3656d0D6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the size of our unrolled RNN."
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "GWkEEHrN0D6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "cs=8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "3-eDNJWC0D6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "H1-k3QO00D6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Rd_iXzif0D7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create a list of the next character in each of these series. This will be the labels for our model."
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Ryk9-vLJ0D7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "dfhS46J00D7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "RQLRylQO0D7p",
        "colab_type": "code",
        "outputId": "88d48398-02fd-4911-e48c-ada7a4ef49de",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600884, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "_JbBPXs70D75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.stack(c_out_dat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "3NYXieDi0D8E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So each column below is one series of 8 characters from the text."
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "gy1-bXP90D8Q",
        "colab_type": "code",
        "outputId": "f0f5435b-0319-4bdb-f9cc-dcbe26c9c2db",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xs[:cs,:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
              "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
              "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
              "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
              "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
              "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
              "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
              "       [ 1,  1,  1, 43, 45, 40, 40, 39]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "z9_U26qT0D8k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and this is the next character after each sequence."
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "i3J3F72z0D8o",
        "colab_type": "code",
        "outputId": "adf411a1-8440-42a9-f8be-70bb8c7b87b5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y[:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1, 43, 45, 40, 40, 39, 43])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "CAeaPr8-0D92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "XA1N2Pv70D98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(idx)-cs-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_qTOGDoA0D-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFpdj7VI0D-s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopModel(nn.Module):\n",
        "    # This is an RNN!\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = F.relu(self.l_in(self.e(c)))\n",
        "            h = F.tanh(self.l_hidden(h+inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "De5mGhel0D-9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lr5nCZQn0D_L",
        "colab_type": "code",
        "outputId": "e09acc3e-2528-4e39-ac43-dc510a002e41",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d1c8fb012c74fe191921d467c80b5ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       2.02986  1.99268]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTxSKYhW0D_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1PUt39HZ0D_5",
        "colab_type": "code",
        "outputId": "a85fa9f0-8b38-4db9-d8d7-3d5eced8a735",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e4a151c0f274c129e346a22fd4bdece",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.73588  1.75103]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EAPT9NCk0EAd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharLoopConcatModel(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
        "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
        "        for c in cs:\n",
        "            inp = torch.cat((h, self.e(c)), 1)\n",
        "            inp = F.relu(self.l_in(inp))\n",
        "            h = F.tanh(self.l_hidden(inp))\n",
        "        \n",
        "        return F.log_softmax(self.l_out(h), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-aS_9Ek0EBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ORje_MU0EBc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)\n",
        "t = m(*V(xs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "krzU0oJb0EBn",
        "colab_type": "code",
        "outputId": "6c02fc28-fc1c-485c-f11c-f78cb5ae11e3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1b3572e787441d8b2e5d80317245596",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.81654  1.78501]                                \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xRBvnzyE0ECO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RqzXCWlA0ECz",
        "colab_type": "code",
        "outputId": "b0729083-c982-4614-cac8-db3ae8c9e555",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9aa67fbb4a2f42509dbe7753bc86d9a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.69008  1.69936]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "kfg4OY3x0EDE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "WmJxwcG-0EDJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Jsv0_LDu0EDV",
        "colab_type": "code",
        "outputId": "fe2a6994-4e54-4f11-901a-9381f82b65a7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "qNqCPpfR0EDm",
        "colab_type": "code",
        "outputId": "5acf01a3-cff6-4582-a74d-6c2f5285e149",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('part of ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'t'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "LkqrQTiQ0EE1",
        "colab_type": "code",
        "outputId": "252454ae-0ac0-421e-c0d3-5fedbe448c66",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('queens a')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "uVfGafFN0EFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN with pytorch"
      ]
    },
    {
      "metadata": {
        "id": "YIWnOPQX0EFu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        \n",
        "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IO2X8MrR0EGe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4oZLBeFK0EGv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xs,yt = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SOi9ToWj0EHE",
        "colab_type": "code",
        "outputId": "5ae81b92-8350-4403-d9a7-c8bcd4bf5b9a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = m.e(V(torch.stack(xs)))\n",
        "t.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 512, 42])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "txK-Vxlu0EHT",
        "colab_type": "code",
        "outputId": "227b55f2-9ae6-490a-e713-bd70e84131fd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ht = V(torch.zeros(1, 512,n_hidden))\n",
        "outp, hn = m.rnn(t, ht)\n",
        "outp.size(), hn.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "metadata": {
        "id": "sF_OKe850EHg",
        "colab_type": "code",
        "outputId": "c3d273b2-e491-42a9-eeba-aff7bdf3284f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t = m(*V(xs)); t.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 85])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "VfJ96HNq0EHu",
        "colab_type": "code",
        "outputId": "17085e2f-9118-47c9-8595-d33cd756a84c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "497078d15ec348149442681039df2e50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.86065  1.84255]                                 \n",
            "[ 1.       1.68014  1.67387]                                 \n",
            "[ 2.       1.58828  1.59169]                                 \n",
            "[ 3.       1.52989  1.54942]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kiWFJw2i0EH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebcWCaOH0EIJ",
        "colab_type": "code",
        "outputId": "08c9dde6-3522-4a44-ef8e-2ac6e91c7821",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a2f7bedaa34de2a40296a07387c1c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "A Jupyter Widget"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.       1.46841  1.50966]                                 \n",
            "[ 1.       1.46482  1.5039 ]                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "vVJkvnLm0EIV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test model"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "RhJTNq5t0EIp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
        "    p = m(*VV(idxs))\n",
        "    i = np.argmax(to_np(p))\n",
        "    return chars[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "WCu2_FMs0EIz",
        "colab_type": "code",
        "outputId": "66b74a58-e884-4dca-fd35-95a5beb3a409",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "ltbELvcD0EI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "1NDsal390EJJ",
        "colab_type": "code",
        "outputId": "2f8e3371-dce2-43b1-db4d-b85713e1e7ad",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_next_n('for thos', 40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for those the same the same the same the same th'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "L_NKMNiO0EJU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-output model"
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "Ai8uQCEs0EJY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "rebmrfiU0EJc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take non-overlapping sets of characters this time"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "e0mHGNR50EJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "-wf39IqM0EJq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Then create the exact same thing, offset by 1, as our labels"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "whBakxAd0EJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "Vjwj4AbM0EJ8",
        "colab_type": "code",
        "outputId": "ece50bb9-28f3-4ab5-c2ec-7b4b0c37a105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "xs = np.stack(c_in_dat)\n",
        "xs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200297, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "PQ_Z2H480EKD",
        "colab_type": "code",
        "outputId": "d455b2d3-f4fc-4fdd-e37b-fd5bb475051c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ys = np.stack(c_out_dat)\n",
        "ys.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200297, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "EIkyvSVP0EKm",
        "colab_type": "code",
        "outputId": "d609e80a-81ab-4ba4-d178-3520129f5be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "xs[:cs,:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 42, 29],\n",
              "       [30, 25, 27],\n",
              "       [29,  1,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "ec21HHex0EKw",
        "colab_type": "code",
        "outputId": "24636703-f9e5-47a4-d9c5-4be741bfd798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "ys[:cs,:cs]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[42, 29, 30],\n",
              "       [25, 27, 29],\n",
              "       [ 1,  1,  1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "Js5nZItx0EK6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create and train model"
      ]
    },
    {
      "metadata": {
        "id": "pbGfR8In0EK9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_idx = get_cv_idxs(len(xs)-cs-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGKR-ajU0ELE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nNdG0YZr0ELK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        \n",
        "    def forward(self, *cs):\n",
        "        bs = cs[0].size(0)\n",
        "        h = V(torch.zeros(1, bs, n_hidden))\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp,h = self.rnn(inp, h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aSP4JNJX0ELR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BKEvlNz0ELZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "it = iter(md.trn_dl)\n",
        "*xst,yt = next(it)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUH9yTKh0ELf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nll_loss_seq(inp, targ):\n",
        "    sl,bs,nh = inp.size()\n",
        "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
        "    return F.nll_loss(inp.view(-1,nh), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YTS7p_lb0ELn",
        "colab_type": "code",
        "outputId": "6d5aecff-1c38-4139-ead2-7326ef3164fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b831a4498fe4a22a3c1a98f64f14d64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.355994   2.326572  \n",
            "    1      2.238234   2.226911  \n",
            "    2      2.180176   2.181392  \n",
            "    3      2.150363   2.158499  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.1585])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "hgJUtgFl0ELx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XDK7Bc020EL6",
        "colab_type": "code",
        "outputId": "f31d03fb-ea39-474b-c735-3ab6861ca1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 1, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa4bb203abd94e1d88e0aa1cb9787ce1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.120463   2.138606  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.13861])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "heading_collapsed": true,
        "id": "hNpW-PpF0EMA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Identity init!"
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "qd9Q5w0q0EMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "ieVGe2Ga0EMH",
        "colab_type": "code",
        "outputId": "d923b02f-e09c-4755-deb2-8c3ff4852017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    1     0     0  ...      0     0     0\n",
              "    0     1     0  ...      0     0     0\n",
              "    0     0     1  ...      0     0     0\n",
              "       ...          ⋱          ...       \n",
              "    0     0     0  ...      1     0     0\n",
              "    0     0     0  ...      0     1     0\n",
              "    0     0     0  ...      0     0     1\n",
              "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "scrolled": false,
        "id": "3JP7er6Y0EMP",
        "colab_type": "code",
        "outputId": "cf603654-cb04-4193-cc65-ee89769a839c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95368204d0734e2aacc79a270898e2f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.270453   2.258912  \n",
            "    1      2.218625   2.224396  \n",
            "    2      2.203576   2.202711  \n",
            "    3      2.188805   2.204043  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.20404])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "hidden": true,
        "id": "0Gc-ECey0EMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "hidden": true,
        "id": "oB-VdD_x0EMe",
        "colab_type": "code",
        "outputId": "3f160220-8050-4027-c2fd-713eb8ad9fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, nll_loss_seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f60586e65fe5445c8baf8bd84633f918",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      2.074014   2.102601  \n",
            "    1      2.062794   2.094643  \n",
            "    2      2.053455   2.09168   \n",
            "    3      2.060589   2.088715  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([2.08871])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "6YJ6zw450EMk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stateful model"
      ]
    },
    {
      "metadata": {
        "id": "itmnshNQ0EMn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ]
    },
    {
      "metadata": {
        "id": "wjcfgWhZ4uV7",
        "colab_type": "code",
        "outputId": "a1f64599-3327-40e7-ec19-ca74fbb3b54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls TRN/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DN--BoVh4tzE",
        "colab_type": "code",
        "outputId": "4dcc6835-ccb0-4f46-8361-fa43cd07856c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd  data/nietzsche/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/nietzsche\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7WWdf0dH0EMq",
        "colab_type": "code",
        "outputId": "ee8da5d0-09de-42d9-b1b3-47408c4ef0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from torchtext import vocab, data\n",
        "\n",
        "from fastai.nlp import *\n",
        "from fastai.lm_rnn import *\n",
        "\n",
        "PATH='/content/data/nietzsche/'\n",
        "\n",
        "TRN_PATH = 'TRN/'\n",
        "VAL_PATH = 'VAL/'\n",
        "TRN = f'{PATH}{TRN_PATH}'\n",
        "VAL = f'{PATH}{VAL_PATH}'\n",
        "\n",
        "# Note: The student needs to practice her shell skills and prepare her own dataset before proceeding:\n",
        "# - trn/trn.txt (first 80% of nietzsche.txt)\n",
        "# - val/val.txt (last 20% of nietzsche.txt)\n",
        "\n",
        "%ls {PATH}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OC6sC0JyBb6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8de830f5-c860-4472-cfd7-26b12d0dae2a"
      },
      "cell_type": "code",
      "source": [
        "# TRN\n",
        "!ls "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qvWxSuht9chD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! mkdir VAL\n",
        "! mkdir TRN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9Jpm6-C6Pa_",
        "colab_type": "code",
        "outputId": "6290839a-252e-4339-92f8-1518828c09b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(text))\n",
        "print(.8* len(text))\n",
        "print()\n",
        "600893  *.8\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600893\n",
            "480714.4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "480714.4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "K6Rvz4uq5EMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !split -l 7948 --additional-suffix=.txt nietzsche.txt trn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QppKN4VO5Dtv",
        "colab_type": "code",
        "outputId": "27d8e66a-ac34-4f61-b136-a420fdad2be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# ! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nietzsche.txt  TRN  trnaa.txt  trnab.txt  VAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ivmjTA73_H0m",
        "colab_type": "code",
        "outputId": "e1f49cde-6cb6-475b-8e50-24daf61061b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# ! mv -v  trnab.txt val.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed 'trnab.txt' -> 'val.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jJ_VC-fPCFjd",
        "colab_type": "code",
        "outputId": "ced0c8bb-8595-4f07-9972-8d3b6571b283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/data/nietzsche/TRN'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "IGFw8q1e0EMx",
        "colab_type": "code",
        "outputId": "f4c519ed-27de-466a-e944-6283db1d2e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd /content/data/nietzsche"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/nietzsche\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jwzIl276ByHv",
        "colab_type": "code",
        "outputId": "47278b04-f1eb-4d8c-a459-6114bc3fa8b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed '/content/data/nietzsche/val.txt' -> '/content/data/nietzsche/VAL/val.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T1TaGd6g-b-V",
        "colab_type": "code",
        "outputId": "bd69f8c1-5347-43f4-9ad9-b0444e6beb37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls TRN/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fdxb35A--8m1",
        "colab_type": "code",
        "outputId": "c07cd0fa-9095-40a9-ae64-9454ae24b61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(text[480714:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "9-1EPM87_rcH",
        "colab_type": "code",
        "outputId": "b365d662-817e-40f6-9ab8-7a4073a48621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gJ-oaS3P-kmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%rm /content/data/nietzsche/TRN/trn.txt\n",
        "%rm /content/data/nietzsche/VAL/val.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8pEZmfiz-05B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f= open(\"trn.txt\",\"w+\")\n",
        "for i in range(len(text[:530000])):\n",
        "     f.write(text[i])\n",
        "f.close() \n",
        "\n",
        "f= open(\"val.txt\",\"w+\")\n",
        "for i in range(len(text[530000:])):\n",
        "     f.write(text[i])\n",
        "f.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4MoaagUGBxoC",
        "colab_type": "code",
        "outputId": "2b50e76a-17b6-4136-ee31-ebb5a56d6cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# ! wc -m  val.txt\n",
        "! mv -v /content/data/nietzsche/val.txt /content/data/nietzsche/VAL/\n",
        "! mv -v /content/data/nietzsche/trn.txt /content/data/nietzsche/TRN/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed '/content/data/nietzsche/val.txt' -> '/content/data/nietzsche/VAL/val.txt'\n",
            "renamed '/content/data/nietzsche/trn.txt' -> '/content/data/nietzsche/TRN/trn.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qNm40pctCLVW",
        "colab_type": "code",
        "outputId": "1b1ff7dc-6143-4081-a40e-c6541f5a980c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "ls TRN/  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ncsZAd3o0EM8",
        "colab_type": "code",
        "outputId": "f06e1615-64fe-4719-99fd-26a7e23f1b69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True, tokenize=list)\n",
        "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
        "\n",
        "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
        "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
        "\n",
        "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1017, 55, 1, 521287)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "6LtbxpMd0ENG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ]
    },
    {
      "metadata": {
        "id": "VVD6cQzY0ENI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        self.vocab_size = vocab_size\n",
        "        super().__init__()\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i67D6vGQ0ENN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "YKF7HOtb0ENS",
        "colab_type": "code",
        "outputId": "d17e5170-35b8-472e-9ad7-3a3f18884df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b93c013ef4594a8dae3be97a1e1a7b3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.877696   1.829953  \n",
            "    1      1.696754   1.666223  \n",
            "    2      1.618095   1.589783  \n",
            "    3      1.564217   1.534397  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.5344])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "I3OgRZGw0ENa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "f7e78cee-387b-473c-faae-3c3a2bf3e83f"
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)\n",
        "\n",
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e464076ebb114713abd55e324457641d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.484162   1.486433  \n",
            "    1      1.486898   1.478987  \n",
            "    2      1.482042   1.472488  \n",
            "    3      1.481383   1.469501  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.4695])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "eFgc3FPg0ENh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNN loop"
      ]
    },
    {
      "metadata": {
        "id": "29s2zkK70ENj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source\n",
        "\n",
        "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d27j1l-H0ENo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulRnn2(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp = []\n",
        "        o = self.h\n",
        "        for c in cs: \n",
        "            o = self.rnn(self.e(c), o)\n",
        "            outp.append(o)\n",
        "        outp = self.l_out(torch.stack(outp))\n",
        "        self.h = repackage_var(o)\n",
        "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7XriOI740ENt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "5x0pCpkG0ENy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 4, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MqPl0Fxt0EN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ]
    },
    {
      "metadata": {
        "id": "E4wzYDX70EN7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmtjtzfb0EOB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# From the pytorch source code - for reference\n",
        "\n",
        "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
        "    gi = F.linear(input, w_ih, b_ih)\n",
        "    gh = F.linear(hidden, w_hh, b_hh)\n",
        "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
        "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
        "\n",
        "    resetgate = F.sigmoid(i_r + h_r)\n",
        "    inputgate = F.sigmoid(i_i + h_i)\n",
        "    newgate = F.tanh(i_n + resetgate * h_n)\n",
        "    return newgate + inputgate * (hidden - newgate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XwIqWDZG0EOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
        "\n",
        "opt = optim.Adam(m.parameters(), 1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "I9cYQnYQ0EPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 6, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NctTx4PY0EPS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "set_lrs(opt, 1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "dxcZCZ2I0EPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 3, opt, F.nll_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iBjOjo1S0EPj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Putting it all together: LSTM"
      ]
    },
    {
      "metadata": {
        "id": "iiTChS_40EPt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai import sgdr\n",
        "\n",
        "n_hidden=512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IRei9R2k0EP1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CharSeqStatefulLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
        "        super().__init__()\n",
        "        self.vocab_size,self.nl = vocab_size,nl\n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "        self.init_hidden(bs)\n",
        "        \n",
        "    def forward(self, cs):\n",
        "        bs = cs[0].size(0)\n",
        "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
        "        outp,h = self.rnn(self.e(cs), self.h)\n",
        "        self.h = repackage_var(h)\n",
        "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
        "    \n",
        "    def init_hidden(self, bs):\n",
        "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
        "                  V(torch.zeros(self.nl, bs, n_hidden)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HImN1KPk0EP8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
        "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FcRwC0V10EQD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{PATH}models', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOA2m7Jj0EQL",
        "colab_type": "code",
        "outputId": "c3fc7029-173a-476c-8a24-8d94d186bae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "fit(m, md, 2, lo.opt, F.nll_loss)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "191da296d738432eae12fe893e86fb73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=2, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.806121   1.711537  \n",
            "    1      1.715098   1.611963  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.61196])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "SpjAzdrB0EQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "d67c15f9-9cc2-46ef-950a-a036acdd7b10"
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97cd760eaa3645ed9ef3a2caa38626dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=15, style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.525274   1.434996  \n",
            "    1      1.576462   1.478579  \n",
            "    2      1.454153   1.370709  \n",
            "    3      1.600508   1.498637  \n",
            "    4      1.511944   1.42372   \n",
            "    5      1.441898   1.358021  \n",
            "    6      1.381154   1.30435   \n",
            "    7      1.595178   1.491192  \n",
            "    8      1.544926   1.45098   \n",
            "    9      1.514823   1.424978  \n",
            "    10     1.468223   1.38548   \n",
            "    11     1.433429   1.344455  \n",
            "    12     1.379225   1.302261  \n",
            "    13     1.333929   1.259723  \n",
            "    14     1.300044   1.235799  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1.2358])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "IdwHbYoV0EQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1248
        },
        "outputId": "bff4c923-4d58-4a6d-c1ea-992dca7afc78"
      },
      "cell_type": "code",
      "source": [
        "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
        "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
        "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "935ca46e6ec744c99e673cd9a7a1e246",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=63, style=ProgressStyle(description_width='initia…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   \n",
            "    0      1.291347   1.231377  \n",
            "    1      1.29596    1.226804  \n",
            "    2      1.287933   1.224325  \n",
            "    3      1.295655   1.221025  \n",
            "    4      1.287611   1.214985  \n",
            "    5      1.276204   1.210892  \n",
            "    6      1.277007   1.209524  \n",
            "    7      1.282942   1.207734  \n",
            "    8      1.269476   1.202194  \n",
            "    9      1.268469   1.194825  \n",
            "    10     1.255592   1.187848  \n",
            "    11     1.251171   1.182679  \n",
            "    12     1.246463   1.178725  \n",
            "    13     1.243161   1.176739  \n",
            "    14     1.243858   1.175755  \n",
            "    15     1.248794   1.177576  \n",
            "    16     1.249167   1.171286  \n",
            "    17     1.238075   1.164544  \n",
            "    18     1.236175   1.156244  \n",
            "    19     1.226105   1.14902   \n",
            "    20     1.215867   1.141634  \n",
            "    21     1.212123   1.134026  \n",
            "    22     1.205074   1.12655   \n",
            "    23     1.195847   1.120786  \n",
            "    24     1.187793   1.115147  \n",
            "    25     1.182869   1.10986   \n",
            "    26     1.17906    1.10589   \n",
            "    27     1.180506   1.102729  \n",
            "    28     1.179099   1.100282  \n",
            "    29     1.172138   1.099561  \n",
            "    30     1.17172    1.098937  \n",
            "    31     1.176127   1.098811  \n",
            "    32     1.184524   1.105611  \n",
            "    33     1.181419   1.098519  \n",
            "    34     1.176301   1.090094  \n",
            "    35     1.171577   1.082028  \n",
            "    36     1.155983   1.073327  \n",
            "    37     1.1538     1.064579  \n",
            "    38     1.145114   1.05722   \n",
            "    39     1.130766   1.049858  \n",
            "    40     1.131461   1.041766  \n",
            "    41     1.130856   1.03449   \n",
            "    42     1.113197   1.024383  \n",
            "    43     1.106825   1.016965  \n",
            "    44     1.112518   1.009819  \n",
            "    45     1.097571   1.0015    \n",
            "    46     1.094496   0.994307  \n",
            "    47     1.087747   0.987649  \n",
            "    48     1.074193   0.980605  \n",
            "    49     1.07551    0.97547   \n",
            "    50     1.069336   0.970355  \n",
            "    51     1.058365   0.964223  \n",
            "    52     1.053211   0.959922  \n",
            "    53     1.055852   0.95586   \n",
            "    54     1.048002   0.951311  \n",
            "    55     1.047648   0.947588  \n",
            "    56     1.047019   0.945004  \n",
            "    57     1.045623   0.942796  \n",
            "    58     1.037413   0.940627  \n",
            "    59     1.039826   0.938779  \n",
            "    60     1.038045   0.938078  \n",
            "    61     1.034038   0.936788  \n",
            "    62     1.035417   0.936391  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.93639])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "FLV7-JHr0EQt",
        "colab_type": "code",
        "outputId": "b0df8ef9-fe4a-4f1e-ea71-6f62926540ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# !ls models\t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cyc_0  cyc_1  cyc_2  cyc_3  cyc_4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3BzJIo8bLfQQ",
        "colab_type": "code",
        "outputId": "4e5ff245-9728-47ea-f630-8665ec71f9c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "# !zip -r /content/data/nietzsche/models.zip /content/data/nietzsche/models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/data/nietzsche/models/ (stored 0%)\n",
            "  adding: content/data/nietzsche/models/cyc_2 (deflated 6%)\n",
            "  adding: content/data/nietzsche/models/cyc_4 (deflated 7%)\n",
            "  adding: content/data/nietzsche/models/cyc_0 (deflated 6%)\n",
            "  adding: content/data/nietzsche/models/cyc_1 (deflated 6%)\n",
            "  adding: content/data/nietzsche/models/cyc_3 (deflated 6%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OFpwJKzCLezM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5DD_k-SMUAm",
        "colab_type": "code",
        "outputId": "75e61bb1-8ec5-4f1d-af90-9b4a69fb6e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "# files.download(\"/content/data/nietzsche/models.zip\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 43432, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 32970, 0, 0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
            "    self.handle()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
            "    self.handle_one_request()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
            "    method()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
            "    self.copyfile(f, self.wfile)\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
            "    shutil.copyfileobj(source, outputfile)\n",
            "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
            "    fdst.write(buf)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
            "    self._sock.sendall(b)\n",
            "ConnectionResetError: [Errno 104] Connection reset by peer\n",
            "----------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XPnzPDze0EQ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "id": "1m2dF_Uh0ERA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next(inp):\n",
        "    idxs = TEXT.numericalize(inp)\n",
        "    p = m(VV(idxs.transpose(0,1)))\n",
        "    r = torch.multinomial(p[-1].exp(), 1)\n",
        "    return TEXT.vocab.itos[to_np(r)[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "RvWmNhGL0ERH",
        "colab_type": "code",
        "outputId": "b1d7ed8a-2592-4822-92ca-f45a79841507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "get_next('for thos')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "utKghGao0ERT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_next_n(inp, n):\n",
        "    res = inp\n",
        "    for i in range(n):\n",
        "        c = get_next(inp)\n",
        "        res += c\n",
        "        inp = inp[1:]+c\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqbxzbYi0ERd",
        "colab_type": "code",
        "outputId": "c9c74399-ff6f-426f-ac96-ae9b28858983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "print(get_next_n('for thos', 400))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for those wrong andforms of mankind himself.97=v'een corresponsible,more permitted with innature of society, inclination; now, disaxmuth it. i can not better and cratic(of self-halvenge-hjourism, were disguise, and great and that one praisecty and sexual courage, towardswith:it will notice out of this maic, thereby the closely difference (say to you? \"hencarlarisement-greatnong men. that peresses, and tri\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CmzCl8oy0ERm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}