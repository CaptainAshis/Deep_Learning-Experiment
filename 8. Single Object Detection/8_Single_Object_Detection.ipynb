{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson8_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "5HqrgWvM3bed"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NlpURSyM3bYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e8b28e8-e04d-426b-c11a-36dcf945ae6f"
      },
      "cell_type": "code",
      "source": [
        "# !pip install https://github.com/fastai/fastai/archive/master.zip\n",
        "!pip install fastai==0.7.0\n",
        "!pip install torchtext==0.2.3\n",
        "!pip install opencv-python\n",
        "!apt update && apt install -y libsm6 libxext6\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torchvision\n",
        "!mkdir data\n",
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar -P data/\n",
        "!wget https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip -P data/\n",
        "!tar -xf data/VOCtrainval_06-Nov-2007.tar -C data/\n",
        "!unzip data/PASCAL_VOC.zip -d data/\n",
        "!rm -rf data/PASCAL_VOC.zip data/VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K    100% |████████████████████████████████| 496.4MB 28kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 496.4MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)\n",
            "\u001b[?25hRequirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)\n",
            "Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.2)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)\n",
            "Collecting bcolz (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    34% |███████████                     | 501kB 9.5MB/s eta 0:00:01Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.2)\n",
            "Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)\n",
            "Collecting bcolz (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 8.1MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.6)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Collecting jedi (from fastai==0.7.0)\n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.6)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)\n",
            "Collecting jedi (from fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/bc/54d53f5bc4658380d0eca9055d72be4df45e5bfd91a4bac97da224a92553/jedi-0.13.2-py2.py3-none-any.whl (177kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.5.20)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.9)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.28.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.13)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/bc/54d53f5bc4658380d0eca9055d72be4df45e5bfd91a4bac97da224a92553/jedi-0.13.2-py2.py3-none-any.whl (177kB)\n",
            "\u001b[K    100% |████████████████████████████████| 184kB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.5.20)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.9)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.28.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.13)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)\n",
            "Collecting sklearn-pandas (from fastai==0.7.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)\n",
            "Collecting sklearn-pandas (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/48/4e1461d828baf41d609efaa720d20090ac6ec346b5daad3c88e243e2207e/sklearn_pandas-1.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (7.4.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/48/4e1461d828baf41d609efaa720d20090ac6ec346b5daad3c88e243e2207e/sklearn_pandas-1.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (7.4.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)\n",
            "Collecting pandas-summary (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/00/f7b4d7fd901db9a79d63e88000bd1e12efba4f5fb52608f906d7fea2b18f/pandas_summary-0.0.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.0.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.3.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (17.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from html5lib->fastai==0.7.0) (1.11.0)\n",
            "Collecting pyarrow>=0.4.0 (from feather-format->fastai==0.7.0)\n",
            "Collecting pandas-summary (from fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/00/f7b4d7fd901db9a79d63e88000bd1e12efba4f5fb52608f906d7fea2b18f/pandas_summary-0.0.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.0.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.3.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (17.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from html5lib->fastai==0.7.0) (1.11.0)\n",
            "Collecting pyarrow>=0.4.0 (from feather-format->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/be/8682e7f6c12dd42f31f32b18d5d61b4f578f12aaa9058081aef954a481d3/pyarrow-0.12.0-cp36-cp36m-manylinux1_x86_64.whl (12.5MB)\n",
            "\u001b[K    33% |██████████▋                     | 4.1MB 37.7MB/s eta 0:00:01\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/be/8682e7f6c12dd42f31f32b18d5d61b4f578f12aaa9058081aef954a481d3/pyarrow-0.12.0-cp36-cp36m-manylinux1_x86_64.whl (12.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 12.5MB 2.7MB/s \n",
            "\u001b[K    100% |████████████████████████████████| 12.5MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.1)\n",
            "Collecting mizani>=0.5.2 (from plotnine->fastai==0.7.0)\n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.1)\n",
            "Collecting mizani>=0.5.2 (from plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/00/f9b9334c94fe0f5267c81697b3f8a85b360144b3840f08526344c4dcae72/mizani-0.5.3-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.6MB/s \n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/00/f9b9334c94fe0f5267c81697b3f8a85b360144b3840f08526344c4dcae72/mizani-0.5.3-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.6MB/s \n",
            "\u001b[?25hCollecting descartes>=1.1.0 (from plotnine->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/b6/1ed2eb03989ae574584664985367ba70cd9cf8b32ee8cad0e8aaeac819f3/descartes-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension->fastai==0.7.0) (5.2.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (4.4.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.4.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (6.0.0)\n",
            "\u001b[?25hCollecting descartes>=1.1.0 (from plotnine->fastai==0.7.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/b6/1ed2eb03989ae574584664985367ba70cd9cf8b32ee8cad0e8aaeac819f3/descartes-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension->fastai==0.7.0) (5.2.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (4.4.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.4.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (6.0.0)\n",
            "Collecting parso>=0.3.0 (from jedi->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/95/917fbfaca4c173651cb8f02bd50712414a0e2a154c8b7077a80027c0864b/parso-0.3.3-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 28.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pandas->fastai==0.7.0) (0.20.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.4)\n",
            "Collecting parso>=0.3.0 (from jedi->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/95/917fbfaca4c173651cb8f02bd50712414a0e2a154c8b7077a80027c0864b/parso-0.3.3-py2.py3-none-any.whl (93kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 28.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pandas->fastai==0.7.0) (0.20.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==0.7.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (40.8.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)\n",
            "Collecting palettable (from mizani>=0.5.2->plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/8a/84537c0354f0d1f03bf644b71bf8e0a50db9c1294181905721a5f3efbf66/palettable-3.1.1-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==0.7.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (40.8.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)\n",
            "Collecting palettable (from mizani>=0.5.2->plotnine->fastai==0.7.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/8a/84537c0354f0d1f03bf644b71bf8e0a50db9c1294181905721a5f3efbf66/palettable-3.1.1-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (4.4.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension->fastai==0.7.0) (0.8.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.5.0)\n",
            "Building wheels for collected packages: feather-format, bcolz\n",
            "Building wheels for collected packages: feather-format, bcolz\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/85/7d/12/2dfa5c0195f921ac935f5e8f27deada74972edc0ae9988a9c1\n",
            "  Building wheel for feather-format (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/85/7d/12/2dfa5c0195f921ac935f5e8f27deada74972edc0ae9988a9c1\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built feather-format bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built feather-format bcolz\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mmizani 0.5.3 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.5.1 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: isoweek, pyarrow, feather-format, palettable, mizani, descartes, plotnine, torch, bcolz, parso, jedi, sklearn-pandas, pandas-summary, fastai\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mmizani 0.5.3 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mplotnine 0.5.1 has requirement pandas>=0.23.4, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: isoweek, pyarrow, feather-format, palettable, mizani, descartes, plotnine, torch, bcolz, parso, jedi, sklearn-pandas, pandas-summary, fastai\n",
            "  Found existing installation: torch 1.0.0\n",
            "  Found existing installation: torch 1.0.0\n",
            "    Uninstalling torch-1.0.0:\n",
            "    Uninstalling torch-1.0.0:\n",
            "      Successfully uninstalled torch-1.0.0\n",
            "      Successfully uninstalled torch-1.0.0\n",
            "  Found existing installation: fastai 1.0.42\n",
            "  Found existing installation: fastai 1.0.42\n",
            "    Uninstalling fastai-1.0.42:\n",
            "      Successfully uninstalled fastai-1.0.42\n",
            "    Uninstalling fastai-1.0.42:\n",
            "      Successfully uninstalled fastai-1.0.42\n",
            "Successfully installed bcolz-1.2.1 descartes-1.1.0 fastai-0.7.0 feather-format-0.4.0 isoweek-1.3.3 jedi-0.13.2 mizani-0.5.3 palettable-3.1.1 pandas-summary-0.0.6 parso-0.3.3 plotnine-0.5.1 pyarrow-0.12.0 sklearn-pandas-1.8.0 torch-0.3.1\n",
            "Successfully installed bcolz-1.2.1 descartes-1.1.0 fastai-0.7.0 feather-format-0.4.0 isoweek-1.3.3 jedi-0.13.2 mizani-0.5.3 palettable-3.1.1 pandas-summary-0.0.6 parso-0.3.3 plotnine-0.5.1 pyarrow-0.12.0 sklearn-pandas-1.8.0 torch-0.3.1\n",
            "Collecting torchtext==0.2.3\n",
            "Collecting torchtext==0.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (1.22)\n",
            "Building wheels for collected packages: torchtext\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3) (2.18.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3) (1.22)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.2.3\n",
            "Successfully installed torchtext-0.2.3\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.14.6)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,609 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,609 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [147 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [147 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [339 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [339 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [679 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [679 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [929 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [929 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [3,650 B]\n",
            "Fetched 2,352 kB in 4s (592 kB/s)\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [3,650 B]\n",
            "Fetched 2,352 kB in 4s (592 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "22 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsm6 is already the newest version (2:1.2.2-1).\n",
            "libxext6 is already the newest version (2:1.3.3-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsm6 is already the newest version (2:1.2.2-1).\n",
            "libxext6 is already the newest version (2:1.3.3-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K    0% |                                | 2.0MB 57.0MB/s eta 0:00:11Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 592.3MB 872kB/s \n",
            "\u001b[K    100% |████████████████████████████████| 592.3MB 872kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.1\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.1\n",
            "    Uninstalling torch-0.3.1:\n",
            "      Successfully uninstalled torch-0.3.1\n",
            "    Uninstalling torch-0.3.1:\n",
            "      Successfully uninstalled torch-0.3.1\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    99% |████████████████████████████████| 2.0MB 61.1MB/s eta 0:00:01\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1\n",
            "Successfully installed pillow-5.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--2019-02-11 03:50:55--  http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar [following]\n",
            "--2019-02-11 03:50:56--  https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
            "HTTP request sent, awaiting response... --2019-02-11 03:50:55--  http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar [following]\n",
            "--2019-02-11 03:50:56--  https://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 460032000 (439M) [application/octet-stream]\n",
            "Saving to: ‘data/VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "          VOCtrainv   0%[                    ]       0  --.-KB/s               200 OK\n",
            "Length: 460032000 (439M) [application/octet-stream]\n",
            "Saving to: ‘data/VOCtrainval_06-Nov-2007.tar’\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  6.93MB/s    in 5m 29s  \n",
            "\n",
            "2019-02-11 03:56:26 (1.33 MB/s) - ‘data/VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n",
            "VOCtrainval_06-Nov- 100%[===================>] 438.72M  6.93MB/s    in 5m 29s  \n",
            "\n",
            "2019-02-11 03:56:26 (1.33 MB/s) - ‘data/VOCtrainval_06-Nov-2007.tar’ saved [460032000/460032000]\n",
            "\n",
            "--2019-02-11 03:56:36--  https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1998182 (1.9M) [application/zip]\n",
            "Saving to: ‘data/PASCAL_VOC.zip’\n",
            "\n",
            "PASCAL_VOC.zip      100%[===================>]   1.91M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-02-11 03:56:36 (112 MB/s) - ‘data/PASCAL_VOC.zip’ saved [1998182/1998182]\n",
            "\n",
            "--2019-02-11 03:56:36--  https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1998182 (1.9M) [application/zip]\n",
            "Saving to: ‘data/PASCAL_VOC.zip’\n",
            "\n",
            "PASCAL_VOC.zip      100%[===================>]   1.91M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-02-11 03:56:36 (112 MB/s) - ‘data/PASCAL_VOC.zip’ saved [1998182/1998182]\n",
            "\n",
            "Archive:  data/PASCAL_VOC.zip\n",
            "   creating: data/PASCAL_VOC/\n",
            "  inflating: data/PASCAL_VOC/pascal_test2007.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_train2007.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_train2012.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_val2007.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_val2012.json  \n",
            "Archive:  data/PASCAL_VOC.zip\n",
            "   creating: data/PASCAL_VOC/\n",
            "  inflating: data/PASCAL_VOC/pascal_test2007.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_train2007.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_train2012.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_val2007.json  \n",
            "  inflating: data/PASCAL_VOC/pascal_val2012.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kDro9L_e3fnB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k5kyN966-M2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48a3e93-2556-4e64-c7d2-ec43d8026b46"
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (5.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (5.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bc6FsNf_3bYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.conv_learner import *\n",
        "from fastai.dataset import *\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "#from PIL import ImageDraw, ImageFont\n",
        "import PIL\n",
        "from matplotlib import patches, patheffects\n",
        "#torch.cuda.set_device(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YzZExfnCkfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4bf07a-2fcb-4a4e-8c56-c60ce2af2397"
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n",
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iKf9EqhfGU0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746b87bd-19b4-4b67-88c5-c2fc98774b37"
      },
      "cell_type": "code",
      "source": [
        "cd data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OyR9qTTwGU3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038e705a-7d37-4db3-c3db-576a9fbc2c60"
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PASCAL_VOC  VOCdevkit\n",
            "PASCAL_VOC  VOCdevkit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s_BnI5mUGb9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e65266b-17bf-41ae-e720-88ef742c9eb8"
      },
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eXa9-yYaGko6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443a951b-e28d-4f0f-f274-d57b007b2f8b"
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  sample_data\n",
            "data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6D55EEY3bYo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pascal VOC"
      ]
    },
    {
      "metadata": {
        "id": "AbO8vQLG3bYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will be looking at the [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) dataset. It's quite slow, so you may prefer to download from [this mirror](https://pjreddie.com/projects/pascal-voc-dataset-mirror/). There are two different competition/research datasets, from 2007 and 2012. We'll be using the 2007 version. You can use the larger 2012 for better results, or even combine them (but be careful to avoid data leakage between the validation sets if you do this).\n",
        "\n",
        "Unlike previous lessons, we are using the python 3 standard library `pathlib` for our paths and file access. Note that it returns an OS-specific class (on Linux, `PosixPath`) so your output may look a little different. Most libraries than take paths as input can take a pathlib object - although some (like `cv2`) can't, in which case you can use `str()` to convert it to a string."
      ]
    },
    {
      "metadata": {
        "id": "xOjBuxb03bYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PATH = Path('data/PASCAL_VOC')\n",
        "#list(PATH.iterdir())\n",
        "PATH = Path('data')\n",
        "list((PATH/'PASCAL_VOC').iterdir())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xYXyaz8MPu9e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# downloaded = files.download('data/PASCAL_VOC/pascal_train2007.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVAuzMoq3bY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As well as the images, there are also *annotations* - *bounding boxes* showing where each object is. These were hand labeled. The original version were in XML, which is a little hard to work with nowadays, so we uses the more recent JSON version which you can download from [this link](https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip).\n",
        "\n",
        "You can see here how `pathlib` includes the ability to open files (amongst many other capabilities)."
      ]
    },
    {
      "metadata": {
        "id": "N8qvcFhk3bY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json = json.load((PATH/'PASCAL_VOC'/'pascal_train2007.json').open()) # training_json is a dict\n",
        "training_json.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsBviVGp-pu9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json.items()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hIbcd0iAAoJh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(list(training_json)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mSNyvrdqwm1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's helpful to use constants instead of strings, since we get tab-completion and don't mistype."
      ]
    },
    {
      "metadata": {
        "id": "r2A4SlHO3bZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7HMJfgxiHB-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[IMAGES][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uPFvcHfHCJT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[ANNOTATIONS][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "90oGyKCYHCTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[CATEGORIES][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbMJKkfkrB4T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[IMAGES][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YcIGyE7c3bZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[ANNOTATIONS][:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emf99_z93bZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_json[CATEGORIES][:20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zc5tPDqo3bZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FILE_NAME,ID,IMG_ID,CATEGORY_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n",
        "\n",
        "categories = {o[ID]:o['name'] for o in training_json[CATEGORIES]}\n",
        "training_filenames = {o[ID]:o[FILE_NAME] for o in training_json[IMAGES]}\n",
        "training_ids = [o[ID] for o in training_json[IMAGES]]\n",
        "\n",
        "# categories and training_filenames are dicts || training_ids is a list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2GcHfep6AOG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#training_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTLhCfW-3bZb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list((PATH/'VOCdevkit'/'VOC2007').iterdir())\n",
        "#list(('VOCdevkit'/'VOC2007').iterdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TDyc3_1f3bZg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "JPEGS = 'VOCdevkit/VOC2007/JPEGImages'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kg1ZSZHi3bZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMG_PATH = PATH/JPEGS\n",
        "list(IMG_PATH.iterdir())[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APFLZsPVGRHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Each image has a unique ID."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b6VXwxOu3bZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A 'IMAGE' sample key-value pair -  [{'FILE_NAME': '000012.jpg', 'height': 333, 'ID': 12, 'width': 500},\n",
        "im0_d = training_json[IMAGES][0]\n",
        "im0_d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myZ9WD-7GsVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im0_d[FILE_NAME],im0_d[ID] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcCDNPS0Wq3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Python's defaultdict is useful any time you want to have a default dictionary entry for new keys. If you try and access a key that doesn’t exist, it magically makes itself exist and it sets itself equal to the return value of the function you specify (in this case lambda:[])."
      ]
    },
    {
      "metadata": {
        "id": "o-4cvaPS3bZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A 'ANNOTATION' sample key-value pair -\n",
        "# [{'area': 34104,\n",
        "#   'BBOX': [155, 96, 196, 174],\n",
        "#   'category_id': 7,\n",
        "#   'id': 1,\n",
        "#   'ignore': 0,\n",
        "#   'image_id': 12,\n",
        "#   'iscrowd': 0,\n",
        "#   'segmentation': [[155, 96, 155, 270, 351, 270, 351, 96]]},\n",
        " \n",
        "# x, y, width, height -> bottom-left coord (y, x), top-right coord (y+height-1, x+width-1)  \n",
        "  \n",
        "def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
        "\n",
        "training_annotations = collections.defaultdict(lambda:[])\n",
        "for o in training_json[ANNOTATIONS]:\n",
        "    if not o['ignore']:\n",
        "        bb = o[BBOX]\n",
        "        bb = hw_bb(bb)\n",
        "        training_annotations[o[IMG_ID]].append((bb,o[CATEGORY_ID]))\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fYlAR-SKOVSn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for o in training_json[ANNOTATIONS][:1]:\n",
        "    if not o['ignore']:\n",
        "        bb = o[BBOX]\n",
        "bb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aBqxxFvO-v5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb = hw_bb(bb)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6jBiTBHOPS5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw3bV5OiPPNn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations[o[IMG_ID]].append((bb,o[CATEGORY_ID]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcngcR60OVW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(training_annotations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnNtVgkpOC6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_a = training_annotations[im0_d[ID]]; \n",
        "im_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bw1hL3xLODxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im0_a = im_a[0]; im0_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KeZZB0bG3bZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categories[7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Jdt6Toz3bZ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E57Ankwb3bZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categories[15],categories[13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wk4vzIu3bZ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some libs take VOC format bounding boxes, so this let's us convert back when required:"
      ]
    },
    {
      "metadata": {
        "id": "AEQnlqfI3bZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc = [155, 96, 196, 174]\n",
        "bb_fastai = hw_bb(bb_voc) # def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HyYnUUeo3baA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3tTb_aph3baC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f'expected: {bb_voc}, actual: {bb_hw(bb_fastai)}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mj9VL6_G3baG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im = open_image(IMG_PATH/im0_d[FILE_NAME])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6sFtZCn3baH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Matplotlib's `plt.subplots` is a really useful wrapper for creating plots, regardless of whether you have more than one subplot. Note that Matplotlib has an optional object-oriented API which I think is much easier to understand and use (although few examples online use it!)"
      ]
    },
    {
      "metadata": {
        "id": "avLa1ZOm3baJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(im, figsize=None, ax=None):\n",
        "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.imshow(im)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUyWXSpy3baO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A simple but rarely used trick to making text visible regardless of background is to use white text with black outline, or visa versa. Here's how to do it in matplotlib."
      ]
    },
    {
      "metadata": {
        "id": "pwfUflnm3baP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_outline(o, lw):\n",
        "    o.set_path_effects([patheffects.Stroke(\n",
        "        linewidth=lw, foreground='black'), patheffects.Normal()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8CcxTg0l3baS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that `*` in argument lists is the [splat operator](https://stackoverflow.com/questions/5239856/foggy-on-asterisk-in-python). In this case it's a little shortcut compared to writing out `b[-2],b[-1]`."
      ]
    },
    {
      "metadata": {
        "id": "-LGmq-it3baT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_rect(ax, b):\n",
        "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
        "    draw_outline(patch, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BCaq6UcH3baW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_text(ax, xy, txt, sz=14):\n",
        "    text = ax.text(*xy, txt,\n",
        "        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n",
        "    draw_outline(text, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B-PAlX3B3baZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = show_img(im)\n",
        "b = bb_hw(im0_a[0])\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], categories[im0_a[1]]) # b[:2] - > b[0] and b[1]... top left coordinates."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkKlzO6w3bac",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_im(im, ann):\n",
        "    ax = show_img(im, figsize=(16,8))\n",
        "    for b,c in ann:\n",
        "        b = bb_hw(b)\n",
        "        draw_rect(ax, b)\n",
        "        draw_text(ax, b[:2], categories[c], sz=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HnU4APwf3bae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_idx(i):\n",
        "    im_a = training_annotations[i]\n",
        "    im = open_image(IMG_PATH/training_filenames[i])\n",
        "    print(im.shape)\n",
        "    draw_im(im, im_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uR3TtN543bah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "draw_idx(17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HjjmnIx3bal",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Largest item classifier"
      ]
    },
    {
      "metadata": {
        "id": "uC-VHJn-3bal",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A *lambda function* is simply a way to define an anonymous function inline. Here we use it to describe how to sort the annotation for each image - by bounding box size (descending)."
      ]
    },
    {
      "metadata": {
        "id": "1WtFSKzM3bam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get largest\n",
        "def get_largest(b):\n",
        "    if not b: raise Exception()\n",
        "    b = sorted(b, key=lambda x: np.product(x[0][-2:]-x[0][:2]), reverse=True)\n",
        "    return b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PwP4rhk8ek_s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = ([96, 155, 269, 350],16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lym_W-jaeo7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZm4NhDKepAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x[0][-2:] # width x height of the bottom right bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWzNquLifnRf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x[0][:2]  # x & y coord of the top left bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B3VuFbt3frII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.product(x[0][-2:] - x[0][:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-MFFMMVmlUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations.items()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MiVnGwN0Ud-0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Gfo687Vh3bap",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_largest_annotations = {a: get_largest(b) for a,b in training_annotations.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xx6gfUqGVH-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_annotations[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9eJ8hy5Vu0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_largest_annotations[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQl0vqjK3baq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have a dictionary from image id to a single bounding box - the largest for that image."
      ]
    },
    {
      "metadata": {
        "id": "ZqYjqj6a3bar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b,c = training_largest_annotations[23]\n",
        "b = bb_hw(b)\n",
        "ax = show_img(open_image(IMG_PATH/training_filenames[23]), figsize=(5,10))\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], categories[c], sz=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xB4vFCnP3bav",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(PATH/'tmp').mkdir(exist_ok=True)\n",
        "CSV = PATH/'tmp/lrg.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4KrvkRpb3bax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Often it's easiest to simply create a CSV of the data you want to model, rather than trying to create a custom dataset. Here we use Pandas to help us create a CSV of the image filename and class."
      ]
    },
    {
      "metadata": {
        "id": "MuKUMLfP3bay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trn_fns = {o[ID]:o[FILE_NAME] for o in trn_j[IMAGES]}\n",
        "#fn - filename, cat - categories\n",
        "df = pd.DataFrame({'fn': [training_filenames[o] for o in training_ids],\n",
        "    'cat': [categories[training_largest_annotations[o][1]] for o in training_ids]}, columns=['fn','cat'])\n",
        "df.to_csv(CSV, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08UgO6Ji3ba0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model = resnet34\n",
        "sz=224\n",
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2oh3fwh3ba4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From here it's just like Dogs vs Cats!"
      ]
    },
    {
      "metadata": {
        "id": "KovRdPcK3ba4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms, bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-slVSoce3ba6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=next(iter(md.val_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cafZqFNb3ba8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_img(md.val_ds.denorm(to_np(x))[0]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "15NZoqm4yYAA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
        "learn.opt_fn = optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7OuFqFN3bbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(1e-5,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OlvNi32d3bbG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When you LR finder graph looks like this, you can ask for more points on each end:"
      ]
    },
    {
      "metadata": {
        "id": "gK1q_KKe3bbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1HIkEe73bbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot(n_skip=5, n_skip_end=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xt6OE93f3bbM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqWnk1Oj3bbO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 1, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2Ox5Akz3bbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/1000,lr/100,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HAjTeYKF3bbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IhGTyxQI3bbe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rWogh50a3bbi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZzYXpF7w3bbn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkJ55pyF3bbs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy isn't improving much - since many images have multiple different objects, it's going to be impossible to be that accurate."
      ]
    },
    {
      "metadata": {
        "id": "1wa17tCj3bbt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EXRsfEjU3bby",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('clas_one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12-x_3UD3bb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('clas_one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bKIGiETXsG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inside of a model data object, we have a bunch of things which include training data loader and training data set. The main thing to know about data loader is that it is an iterator that each time you grab the next iteration of stuff from it, you get a mini batch.\n",
        "\n",
        "If you want to grab just a single batch, this is how you do it:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# x: independent variable\n",
        "# y: dependent variable\n",
        "x, y = next(iter(md.val_dl))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bNM-yi793bb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y = next(iter(md.val_dl))\n",
        "probs = F.softmax(predict_batch(learn.model, x), -1)\n",
        "x,preds = to_np(x),to_np(probs) # variables to numpy arrays\n",
        "preds = np.argmax(preds, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DAs3raPbZDyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G792LDz93bcE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.denorm(x)[i]\n",
        "    b = md.classes[preds[i]]\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_text(ax, (0,0), b)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXkCRO3P3bcI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's doing a pretty good job of classifying the largest object!"
      ]
    },
    {
      "metadata": {
        "id": "XLjIB2b73bcJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bbox only"
      ]
    },
    {
      "metadata": {
        "id": "xZzkrz8K3bcK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll try to find the bounding box of the largest object. This is simply a regression with 4 outputs. So we can use a CSV with multiple 'labels'."
      ]
    },
    {
      "metadata": {
        "id": "Q7fmHXbE3bcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BB_CSV = PATH/'tmp/bb.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ipdd2c4-3bcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb = np.array([training_largest_annotations[o][0] for o in training_ids])\n",
        "bbs = [' '.join(str(p) for p in o) for o in bb]\n",
        "\n",
        "df = pd.DataFrame({'fn': [training_filenames[o] for o in training_ids], 'bbox': bbs}, columns=['fn','bbox'])\n",
        "df.to_csv(BB_CSV, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOEJWwFX3bcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BB_CSV.open().readlines()[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUToMQ2U3bcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model=resnet34\n",
        "sz=224\n",
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3NaOAZ43bcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set `continuous=True` to tell fastai this is a regression problem, which means it won't one-hot encode the labels, and will use MSE as the default crit.\n",
        "\n",
        "Note that we have to tell the transforms constructor that our labels are coordinates, so that it can handle the transforms correctly.\n",
        "\n",
        "Also, we use CropType.NO because we want to 'squish' the rectangular images into squares, rather than center cropping, so that we don't accidentally crop out some of the objects. (This is less of an issue in something like imagenet, where there is a single object to classify, and it's generally large and centrally located)."
      ]
    },
    {
      "metadata": {
        "id": "SMCGNTtD3bcg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augs = [RandomFlip(), \n",
        "        RandomRotate(30),\n",
        "        RandomLighting(0.1,0.1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zktnGkM1GN-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZlzWapq3bcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vcXsR3eL3bcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    x,y=next(iter(md.aug_dl))\n",
        "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
        "    b = bb_hw(to_np(y[idx]))\n",
        "    print(b)\n",
        "    show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F8AJcB2n3bc2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augs = [RandomFlip(tfm_y=TfmType.COORD),\n",
        "        RandomRotate(30, tfm_y=TfmType.COORD),\n",
        "        RandomLighting(0.1,0.1, tfm_y=TfmType.COORD)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwHnHwRW3bc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hzcf1-y43bc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    x,y=next(iter(md.aug_dl))\n",
        "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
        "    b = bb_hw(to_np(y[idx]))\n",
        "    print(b)\n",
        "    show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoD0acrQa0p3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Note that we have to tell the transforms constructor that our labels are coordinates, so that it can handle the transforms correctly."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QWWOs06x3bdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfm_y = TfmType.COORD\n",
        "augs = [RandomFlip(tfm_y=tfm_y),\n",
        "        RandomRotate(3, p=0.5, tfm_y=tfm_y),\n",
        "        RandomLighting(0.05,0.05, tfm_y=tfm_y)]\n",
        "\n",
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=tfm_y, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, bs=bs, continuous=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iQGqP7m3bdG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fastai let's you use a `custom_head` to add your own module on top of a convnet, instead of the adaptive pooling and fully connected net which is added by default. In this case, we don't want to do any pooling, since we need to know the activations of each grid cell.\n",
        "\n",
        "The final layer has 4 activations, one per bounding box coordinate. Our target is continuous, not categorical, so the MSE loss function used does not do any sigmoid or softmax to the module outputs."
      ]
    },
    {
      "metadata": {
        "id": "7D5Q-dzLb1Kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Flatten()\n",
        "\n",
        "#The previous layer generally has 7x7x512 param in ResNet34, so flatten that out into a single vector."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNY3f2V13bdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "512*7*7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQm9nRXo3bdJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_reg4 = nn.Sequential(Flatten(), nn.Linear(25088,4))\n",
        "learn = ConvLearner.pretrained(f_model, md, custom_head=head_reg4)\n",
        "learn.opt_fn = optim.Adam\n",
        "learn.crit = nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQG_IKXv3bdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RmVKZnqL3bdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(1e-5,100)\n",
        "learn.sched.plot(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WO-DqJ5C3bdV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fADslrSk3bdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 2, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "djNpAPU93bda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/100,lr/10,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J9vFgZjP3bdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7Pl4lfV3bdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jYMsgdHh3bdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bY_cgh03bdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VZx6XECN3bdj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 1, cycle_len=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drEz3tge3bdk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "__0JUgcv3bdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hnq0scFr3bdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y = next(iter(md.val_dl))\n",
        "learn.model.eval()\n",
        "preds = to_np(learn.model(VV(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WiDcbIv_3bdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.denorm(to_np(x))[i]\n",
        "    b = bb_hw(preds[i])\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5rYmeqsw3bdq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Single object detection"
      ]
    },
    {
      "metadata": {
        "id": "Q0-cHqHK3bds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model=resnet34\n",
        "sz=224\n",
        "bs=64\n",
        "\n",
        "val_idxs = get_cv_idxs(len(training_filenames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9il-fvI3bdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms,\n",
        "   bs=bs, continuous=True, val_idxs=val_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlRxBsSg3bdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md2 = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms_from_model(f_model, sz))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AqP4yliD3bdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A dataset can be anything with `__len__` and `__getitem__`. Here's a dataset that adds a 2nd label to an existing dataset:"
      ]
    },
    {
      "metadata": {
        "id": "UEecbfS-3bdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConcatLblDataset(Dataset):\n",
        "    def __init__(self, ds, y2): self.ds,self.y2 = ds,y2\n",
        "    def __len__(self): return len(self.ds)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        x,y = self.ds[i]\n",
        "        return (x, (y,self.y2[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udGOJzIs3bdx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll use it to add the classes to the bounding boxes labels."
      ]
    },
    {
      "metadata": {
        "id": "1JsRno3K3bdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\n",
        "val_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZiQFj0D3bdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_ds2[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qc9mlCOR3bd1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can replace the dataloaders' datasets with these new ones."
      ]
    },
    {
      "metadata": {
        "id": "LiIJR0dC3bd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md.trn_dl.dataset = trn_ds2\n",
        "md.val_dl.dataset = val_ds2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJy-PYxV3bd3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to `denorm`alize the images from the dataloader before they can be plotted."
      ]
    },
    {
      "metadata": {
        "id": "B_KQNp6e3bd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=next(iter(md.val_dl))\n",
        "idx=3\n",
        "ima=md.val_ds.ds.denorm(to_np(x))[idx]\n",
        "b = bb_hw(to_np(y[0][idx])); b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J4uzO6uu3bd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = show_img(ima)\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], md2.classes[y[1][idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5ayuTXr3bd8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need one output activation for each class (for its probability) plus one for each bounding box coordinate. We'll use an extra linear layer this time, plus some dropout, to help us train a more flexible model."
      ]
    },
    {
      "metadata": {
        "id": "ZuFh29Om3bd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_reg4 = nn.Sequential(\n",
        "    Flatten(),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(25088,256),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256,4+len(categories)),\n",
        ")\n",
        "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
        "\n",
        "learn = ConvLearner(md, models)\n",
        "learn.opt_fn = optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QCHvdyQE3bd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def detn_loss(input, target):\n",
        "    bb_t,c_t = target\n",
        "    bb_i,c_i = input[:, :4], input[:, 4:]\n",
        "    bb_i = F.sigmoid(bb_i)*224\n",
        "    # I looked at these quantities separately first then picked a multiplier\n",
        "    #   to make them approximately equal\n",
        "    return F.l1_loss(bb_i, bb_t) + F.cross_entropy(c_i, c_t)*20\n",
        "\n",
        "def detn_l1(input, target):\n",
        "    bb_t,_ = target\n",
        "    bb_i = input[:, :4]\n",
        "    bb_i = F.sigmoid(bb_i)*224\n",
        "    return F.l1_loss(V(bb_i),V(bb_t)).data\n",
        "\n",
        "def detn_acc(input, target):\n",
        "    _,c_t = target\n",
        "    c_i = input[:, 4:]\n",
        "    return accuracy(c_i, c_t)\n",
        "\n",
        "learn.crit = detn_loss\n",
        "learn.metrics = [detn_acc, detn_l1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pww6_AVK3beB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CA5ei_N3beC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtQbtMOT3beD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qB2s5W6I3beH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6TV-fG-3beI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uv3-SBPd3beK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/100, lr/10, lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UmoilWp73beM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-EmHTJtt3beP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=5, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DX2A7mUi3beR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4m3rJkM3beS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg1_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Yxr6jPL3beU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3UNwyI2J3beV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/10, 1, cycle_len=10, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKUa-R7H3beY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCP9qeMK3beZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wX9tJHU-3bea",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = learn.predict()\n",
        "x,_ = next(iter(md.val_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "408rmNAT3bec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.special import expit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0idZld2Q3bec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.ds.denorm(to_np(x))[i]\n",
        "    bb = expit(y[i][:4])*224\n",
        "    b = bb_hw(bb)\n",
        "    c = np.argmax(y[i][4:])\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)\n",
        "    draw_text(ax, b[:2], md2.classes[c])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HqrgWvM3bed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## End"
      ]
    },
    {
      "metadata": {
        "id": "NDo3OVHX3bed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_qluoO0kG-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc = [155, 96, 196, 174]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPfi5Jo_kG7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6H_qJqf3kG5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}